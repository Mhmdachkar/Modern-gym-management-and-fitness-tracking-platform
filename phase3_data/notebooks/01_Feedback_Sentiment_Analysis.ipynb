{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47e95c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2752482578.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    install textblob vaderSentiment wordcloud seaborn plotly\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Fitness Club Feedback Sentiment Analysis\n",
    "# Complete analysis for Google Colab\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# Install required packages\n",
    "!pip install textblob vaderSentiment wordcloud seaborn plotly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Text processing and sentiment analysis\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Interactive plotting\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING AND PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('feedback_data.csv')\n",
    "\n",
    "print(\"ðŸ“Š Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"\\nFeedback types: {df['feedback_type'].unique()}\")\n",
    "print(f\"\\nRating distribution:\\n{df['rating'].value_counts().sort_index()}\")\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day_of_week'] = df['timestamp'].dt.day_name()\n",
    "\n",
    "# Create sentiment categories based on existing sentiment_score\n",
    "def categorize_sentiment(score):\n",
    "    if score >= 0.7:\n",
    "        return 'Positive'\n",
    "    elif score >= 0.3:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "df['sentiment_category'] = df['sentiment_score'].apply(categorize_sentiment)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Sentiment Distribution:\")\n",
    "print(df['sentiment_category'].value_counts())\n",
    "\n",
    "# ============================================================================\n",
    "# SENTIMENT VALIDATION WITH MULTIPLE METHODS\n",
    "# ============================================================================\n",
    "\n",
    "# Initialize sentiment analyzers\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_textblob_sentiment(text):\n",
    "    \"\"\"Get sentiment using TextBlob\"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def get_vader_sentiment(text):\n",
    "    \"\"\"Get sentiment using VADER\"\"\"\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    return scores['compound']\n",
    "\n",
    "def normalize_sentiment(score, method='linear'):\n",
    "    \"\"\"Normalize sentiment scores to 0-1 range\"\"\"\n",
    "    if method == 'linear':\n",
    "        return (score + 1) / 2\n",
    "    elif method == 'sigmoid':\n",
    "        return 1 / (1 + np.exp(-score))\n",
    "\n",
    "# Apply different sentiment analysis methods\n",
    "print(\"ðŸ” Applying multiple sentiment analysis methods...\")\n",
    "\n",
    "df['textblob_sentiment'] = df['feedback_text'].apply(get_textblob_sentiment)\n",
    "df['vader_sentiment'] = df['feedback_text'].apply(get_vader_sentiment)\n",
    "\n",
    "# Normalize scores\n",
    "df['textblob_normalized'] = df['textblob_sentiment'].apply(normalize_sentiment)\n",
    "df['vader_normalized'] = df['vader_sentiment'].apply(normalize_sentiment)\n",
    "\n",
    "# Compare methods\n",
    "sentiment_comparison = df[['sentiment_score', 'textblob_normalized', 'vader_normalized']].corr()\n",
    "print(\"\\nðŸ“ˆ Correlation between sentiment methods:\")\n",
    "print(sentiment_comparison.round(3))\n",
    "\n",
    "# ============================================================================\n",
    "# COMPREHENSIVE SENTIMENT ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def create_sentiment_dashboard():\n",
    "    \"\"\"Create comprehensive sentiment analysis dashboard\"\"\"\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=2,\n",
    "        subplot_titles=[\n",
    "            'Sentiment Distribution by Category',\n",
    "            'Rating vs Sentiment Score',\n",
    "            'Sentiment Trends Over Time',\n",
    "            'Sentiment by Feedback Type',\n",
    "            'Sentiment by Coach',\n",
    "            'Daily Sentiment Patterns'\n",
    "        ],\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "               [{\"colspan\": 2}, None],\n",
    "               [{\"type\": \"bar\"}, {\"type\": \"heatmap\"}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Sentiment distribution\n",
    "    sentiment_counts = df['sentiment_category'].value_counts()\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=sentiment_counts.index, y=sentiment_counts.values,\n",
    "               marker_color=['#ff6b6b', '#ffd93d', '#6bcf7f']),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # 2. Rating vs Sentiment\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df['rating'], y=df['sentiment_score'],\n",
    "                  mode='markers', opacity=0.6,\n",
    "                  marker=dict(size=8, color=df['sentiment_score'],\n",
    "                            colorscale='RdYlGn', showscale=True)),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Time trends\n",
    "    daily_sentiment = df.groupby('date')['sentiment_score'].mean().reset_index()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=daily_sentiment['date'], y=daily_sentiment['sentiment_score'],\n",
    "                  mode='lines+markers', name='Daily Avg Sentiment'),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Sentiment by feedback type\n",
    "    type_sentiment = df.groupby('feedback_type')['sentiment_score'].mean().sort_values(ascending=True)\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=type_sentiment.values, y=type_sentiment.index, orientation='h',\n",
    "               marker_color='lightblue'),\n",
    "        row=3, col=1\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(height=1200, showlegend=False,\n",
    "                     title_text=\"ðŸŽ¯ Comprehensive Sentiment Analysis Dashboard\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard = create_sentiment_dashboard()\n",
    "dashboard.show()\n",
    "\n",
    "# ============================================================================\n",
    "# DETAILED ANALYSIS BY CATEGORIES\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_sentiment_by_category():\n",
    "    \"\"\"Detailed sentiment analysis by different categories\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ” DETAILED SENTIMENT ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. By Feedback Type\n",
    "    print(\"\\n1ï¸âƒ£ SENTIMENT BY FEEDBACK TYPE:\")\n",
    "    type_analysis = df.groupby('feedback_type').agg({\n",
    "        'sentiment_score': ['mean', 'std', 'count'],\n",
    "        'rating': 'mean'\n",
    "    }).round(3)\n",
    "    print(type_analysis)\n",
    "    \n",
    "    # 2. By Rating\n",
    "    print(\"\\n2ï¸âƒ£ SENTIMENT BY RATING:\")\n",
    "    rating_analysis = df.groupby('rating').agg({\n",
    "        'sentiment_score': ['mean', 'std', 'count']\n",
    "    }).round(3)\n",
    "    print(rating_analysis)\n",
    "    \n",
    "    # 3. By Coach (where applicable)\n",
    "    print(\"\\n3ï¸âƒ£ SENTIMENT BY COACH:\")\n",
    "    coach_feedback = df[df['coach_id'].notna()]\n",
    "    if not coach_feedback.empty:\n",
    "        coach_analysis = coach_feedback.groupby('coach_id').agg({\n",
    "            'sentiment_score': ['mean', 'std', 'count'],\n",
    "            'rating': 'mean'\n",
    "        }).round(3)\n",
    "        print(coach_analysis)\n",
    "    \n",
    "    # 4. Temporal Analysis\n",
    "    print(\"\\n4ï¸âƒ£ TEMPORAL SENTIMENT PATTERNS:\")\n",
    "    temporal_analysis = df.groupby('day_of_week')['sentiment_score'].mean().sort_values(ascending=False)\n",
    "    print(\"Average sentiment by day of week:\")\n",
    "    print(temporal_analysis.round(3))\n",
    "    \n",
    "    # 5. Package Analysis\n",
    "    print(\"\\n5ï¸âƒ£ SENTIMENT BY PACKAGE:\")\n",
    "    package_feedback = df[df['package_id'].notna()]\n",
    "    if not package_feedback.empty:\n",
    "        package_analysis = package_feedback.groupby('package_id').agg({\n",
    "            'sentiment_score': ['mean', 'std', 'count'],\n",
    "            'rating': 'mean'\n",
    "        }).round(3)\n",
    "        print(package_analysis)\n",
    "\n",
    "analyze_sentiment_by_category()\n",
    "\n",
    "# ============================================================================\n",
    "# TEXT ANALYSIS AND INSIGHTS\n",
    "# ============================================================================\n",
    "\n",
    "def extract_keywords_by_sentiment():\n",
    "    \"\"\"Extract keywords from positive and negative feedback\"\"\"\n",
    "    \n",
    "    positive_feedback = df[df['sentiment_category'] == 'Positive']['feedback_text'].str.cat(sep=' ')\n",
    "    negative_feedback = df[df['sentiment_category'] == 'Negative']['feedback_text'].str.cat(sep=' ')\n",
    "    \n",
    "    def clean_text(text):\n",
    "        # Convert to lowercase and remove special characters\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "        # Remove common stop words\n",
    "        stop_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'was', 'are', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves'}\n",
    "        words = [word for word in text.split() if word not in stop_words and len(word) > 2]\n",
    "        return ' '.join(words)\n",
    "    \n",
    "    positive_clean = clean_text(positive_feedback)\n",
    "    negative_clean = clean_text(negative_feedback)\n",
    "    \n",
    "    # Get most common words\n",
    "    positive_words = Counter(positive_clean.split()).most_common(15)\n",
    "    negative_words = Counter(negative_clean.split()).most_common(15)\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ KEYWORD ANALYSIS:\")\n",
    "    print(\"\\nâœ… Most common words in POSITIVE feedback:\")\n",
    "    for word, count in positive_words:\n",
    "        print(f\"  â€¢ {word}: {count}\")\n",
    "    \n",
    "    print(\"\\nâŒ Most common words in NEGATIVE feedback:\")\n",
    "    for word, count in negative_words:\n",
    "        print(f\"  â€¢ {word}: {count}\")\n",
    "    \n",
    "    return positive_words, negative_words\n",
    "\n",
    "positive_keywords, negative_keywords = extract_keywords_by_sentiment()\n",
    "\n",
    "# ============================================================================\n",
    "# SENTIMENT TREND ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_sentiment_trends():\n",
    "    \"\"\"Analyze sentiment trends and patterns\"\"\"\n",
    "    \n",
    "    # Daily trends\n",
    "    daily_trends = df.groupby('date').agg({\n",
    "        'sentiment_score': 'mean',\n",
    "        'rating': 'mean',\n",
    "        'feedback_text': 'count'\n",
    "    }).rename(columns={'feedback_text': 'feedback_count'})\n",
    "    \n",
    "    # Weekly patterns\n",
    "    weekly_patterns = df.groupby('day_of_week')['sentiment_score'].mean().reindex([\n",
    "        'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
    "    ])\n",
    "    \n",
    "    # Hourly patterns\n",
    "    hourly_patterns = df.groupby('hour')['sentiment_score'].mean()\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Daily trends\n",
    "    axes[0, 0].plot(daily_trends.index, daily_trends['sentiment_score'], marker='o')\n",
    "    axes[0, 0].set_title('Daily Sentiment Trends')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Average Sentiment Score')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Weekly patterns\n",
    "    weekly_patterns.plot(kind='bar', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Weekly Sentiment Patterns')\n",
    "    axes[0, 1].set_xlabel('Day of Week')\n",
    "    axes[0, 1].set_ylabel('Average Sentiment Score')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Sentiment distribution\n",
    "    df['sentiment_category'].value_counts().plot(kind='pie', ax=axes[1, 0], autopct='%1.1f%%')\n",
    "    axes[1, 0].set_title('Sentiment Distribution')\n",
    "    \n",
    "    # Hourly patterns\n",
    "    hourly_patterns.plot(kind='line', ax=axes[1, 1], marker='o')\n",
    "    axes[1, 1].set_title('Hourly Sentiment Patterns')\n",
    "    axes[1, 1].set_xlabel('Hour of Day')\n",
    "    axes[1, 1].set_ylabel('Average Sentiment Score')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return daily_trends, weekly_patterns, hourly_patterns\n",
    "\n",
    "daily_trends, weekly_patterns, hourly_patterns = analyze_sentiment_trends()\n",
    "\n",
    "# ============================================================================\n",
    "# ACTIONABLE INSIGHTS AND RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_insights():\n",
    "    \"\"\"Generate actionable insights from sentiment analysis\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸŽ¯ ACTIONABLE INSIGHTS & RECOMMENDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Overall sentiment health\n",
    "    overall_sentiment = df['sentiment_score'].mean()\n",
    "    positive_rate = (df['sentiment_category'] == 'Positive').mean() * 100\n",
    "    negative_rate = (df['sentiment_category'] == 'Negative').mean() * 100\n",
    "    \n",
    "    print(f\"\\nðŸ“Š OVERALL SENTIMENT HEALTH:\")\n",
    "    print(f\"  â€¢ Average sentiment score: {overall_sentiment:.3f}\")\n",
    "    print(f\"  â€¢ Positive feedback rate: {positive_rate:.1f}%\")\n",
    "    print(f\"  â€¢ Negative feedback rate: {negative_rate:.1f}%\")\n",
    "    \n",
    "    # Identify problem areas\n",
    "    print(f\"\\nðŸš¨ AREAS NEEDING ATTENTION:\")\n",
    "    \n",
    "    # Low-rated feedback types\n",
    "    low_sentiment_types = df.groupby('feedback_type')['sentiment_score'].mean().sort_values().head(2)\n",
    "    for feedback_type, score in low_sentiment_types.items():\n",
    "        print(f\"  â€¢ {feedback_type}: {score:.3f} average sentiment\")\n",
    "    \n",
    "    # Problematic coaches\n",
    "    if 'coach_id' in df.columns and df['coach_id'].notna().any():\n",
    "        coach_sentiment = df[df['coach_id'].notna()].groupby('coach_id')['sentiment_score'].mean().sort_values()\n",
    "        if len(coach_sentiment) > 0:\n",
    "            worst_coach = coach_sentiment.index[0]\n",
    "            worst_score = coach_sentiment.iloc[0]\n",
    "            print(f\"  â€¢ Coach {worst_coach}: {worst_score:.3f} average sentiment\")\n",
    "    \n",
    "    # Time-based insights\n",
    "    worst_day = weekly_patterns.idxmin()\n",
    "    worst_day_score = weekly_patterns.min()\n",
    "    print(f\"  â€¢ {worst_day}: {worst_day_score:.3f} (lowest sentiment day)\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "    \n",
    "    if overall_sentiment < 0.6:\n",
    "        print(\"  â€¢ Overall sentiment is concerning - conduct comprehensive review\")\n",
    "    \n",
    "    if negative_rate > 20:\n",
    "        print(\"  â€¢ High negative feedback rate - implement immediate action plan\")\n",
    "    \n",
    "    print(\"  â€¢ Focus on addressing recurring issues mentioned in negative feedback\")\n",
    "    print(\"  â€¢ Enhance training for underperforming coaches\")\n",
    "    print(\"  â€¢ Consider adjusting class schedules based on sentiment patterns\")\n",
    "    print(\"  â€¢ Implement follow-up system for negative feedback\")\n",
    "    \n",
    "    # Success stories\n",
    "    print(f\"\\nðŸŽ‰ SUCCESS HIGHLIGHTS:\")\n",
    "    \n",
    "    best_sentiment_type = df.groupby('feedback_type')['sentiment_score'].mean().idxmax()\n",
    "    best_score = df.groupby('feedback_type')['sentiment_score'].mean().max()\n",
    "    print(f\"  â€¢ Best performing area: {best_sentiment_type} ({best_score:.3f})\")\n",
    "    \n",
    "    if 'coach_id' in df.columns and df['coach_id'].notna().any():\n",
    "        best_coach = df[df['coach_id'].notna()].groupby('coach_id')['sentiment_score'].mean().idxmax()\n",
    "        best_coach_score = df[df['coach_id'].notna()].groupby('coach_id')['sentiment_score'].mean().max()\n",
    "        print(f\"  â€¢ Top performing coach: Coach {best_coach} ({best_coach_score:.3f})\")\n",
    "    \n",
    "    best_day = weekly_patterns.idxmax()\n",
    "    best_day_score = weekly_patterns.max()\n",
    "    print(f\"  â€¢ Best day for satisfaction: {best_day} ({best_day_score:.3f})\")\n",
    "\n",
    "generate_insights()\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTIVE MODELING (BONUS)\n",
    "# ============================================================================\n",
    "\n",
    "def create_sentiment_predictor():\n",
    "    \"\"\"Create a simple sentiment prediction model\"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_absolute_error, r2_score\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸ¤– SENTIMENT PREDICTION MODEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Prepare features\n",
    "    feature_df = df.copy()\n",
    "    \n",
    "    # Create dummy variables for categorical features\n",
    "    feature_df = pd.get_dummies(feature_df, columns=['feedback_type', 'day_of_week'])\n",
    "    \n",
    "    # Select features\n",
    "    feature_cols = [col for col in feature_df.columns if col.startswith(('feedback_type_', 'day_of_week_'))]\n",
    "    feature_cols.extend(['rating', 'hour'])\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    model_df = feature_df[feature_cols + ['sentiment_score']].dropna()\n",
    "    \n",
    "    X = model_df[feature_cols]\n",
    "    y = model_df['sentiment_score']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"  â€¢ Mean Absolute Error: {mae:.4f}\")\n",
    "    print(f\"  â€¢ RÂ² Score: {r2:.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 5 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head().iterrows():\n",
    "        print(f\"  â€¢ {row['feature']}: {row['importance']:.4f}\")\n",
    "    \n",
    "    return rf, feature_importance\n",
    "\n",
    "try:\n",
    "    !pip install scikit-learn\n",
    "    model, feature_importance = create_sentiment_predictor()\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn not available. Install with: !pip install scikit-learn\")\n",
    "\n",
    "# ============================================================================\n",
    "# EXPORT RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "def export_results():\n",
    "    \"\"\"Export analysis results\"\"\"\n",
    "    \n",
    "    # Create summary statistics\n",
    "    summary_stats = {\n",
    "        'overall_sentiment_score': df['sentiment_score'].mean(),\n",
    "        'positive_feedback_rate': (df['sentiment_category'] == 'Positive').mean(),\n",
    "        'negative_feedback_rate': (df['sentiment_category'] == 'Negative').mean(),\n",
    "        'total_feedback_count': len(df),\n",
    "        'date_range': f\"{df['timestamp'].min()} to {df['timestamp'].max()}\"\n",
    "    }\n",
    "    \n",
    "    # Save enhanced dataset\n",
    "    df.to_csv('feedback_with_sentiment_analysis.csv', index=False)\n",
    "    \n",
    "    # Save summary\n",
    "    pd.DataFrame([summary_stats]).to_csv('sentiment_analysis_summary.csv', index=False)\n",
    "    \n",
    "    print(\"\\nâœ… Results exported:\")\n",
    "    print(\"  â€¢ feedback_with_sentiment_analysis.csv\")\n",
    "    print(\"  â€¢ sentiment_analysis_summary.csv\")\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "summary = export_results()\n",
    "\n",
    "print(\"\\nðŸŽ‰ Sentiment Analysis Complete!\")\n",
    "print(\"ðŸ“Š Use the generated insights to improve customer satisfaction!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
