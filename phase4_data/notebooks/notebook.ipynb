{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04434333",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully!\n",
      "📅 Analysis Date: 2025-10-02 03:29:05\n",
      "\n",
      "================================================================================\n",
      "📂 LOADING GEO ANALYTICS DATASETS\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'member_geo_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Load member geographic data\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m member_geo_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmember_geo_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Loaded member_geo_data.csv: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmember_geo_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m members\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Load facility locations\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'member_geo_data.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "GEO ANALYTICS - REGIONAL DISTRIBUTION & DEMAND ANALYSIS\n",
    "Step 13: Comprehensive Geographic Analysis for Gym Expansion Strategy\n",
    "=============================================================================\n",
    "\n",
    "This notebook performs:\n",
    "1. Member distribution mapping and density analysis\n",
    "2. Demand pattern analysis across regions\n",
    "3. Accessibility calculations (travel time, distance)\n",
    "4. Market penetration and competitive analysis\n",
    "5. Expansion planning with ROI projections\n",
    "6. Interactive Folium maps for strategic insights\n",
    "\n",
    "Author: Gym Analytics Team\n",
    "Date: October 2025\n",
    "=============================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: ENVIRONMENT SETUP & INSTALLATIONS\n",
    "# ============================================================================\n",
    "\n",
    "!pip install folium geopandas geopy scikit-learn pandas numpy matplotlib seaborn plotly -q\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import geopandas as gpd\n",
    "from geopy.distance import geodesic\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(f\"📅 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: DATA LOADING & VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📂 LOADING GEO ANALYTICS DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load member geographic data\n",
    "member_geo_df = pd.read_csv('member_geo_data.csv')\n",
    "print(f\"\\n✅ Loaded member_geo_data.csv: {member_geo_df.shape[0]} members\")\n",
    "\n",
    "# Load facility locations\n",
    "facility_df = pd.read_csv('facility_locations_data.csv')\n",
    "print(f\"✅ Loaded facility_locations_data.csv: {facility_df.shape[0]} facilities\")\n",
    "\n",
    "# Load market analysis data\n",
    "market_df = pd.read_csv('market_analysis_data.csv')\n",
    "print(f\"✅ Loaded market_analysis_data.csv: {market_df.shape[0]} zip codes\")\n",
    "\n",
    "# Data validation\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"🔍 DATA VALIDATION CHECKS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n1. Missing Values Check:\")\n",
    "print(f\"   Member Data: {member_geo_df.isnull().sum().sum()} missing values\")\n",
    "print(f\"   Facility Data: {facility_df.isnull().sum().sum()} missing values\")\n",
    "print(f\"   Market Data: {market_df.isnull().sum().sum()} missing values\")\n",
    "\n",
    "# Check coordinate ranges\n",
    "print(\"\\n2. Coordinate Validation:\")\n",
    "print(f\"   Latitude range: [{member_geo_df['latitude'].min():.4f}, {member_geo_df['latitude'].max():.4f}]\")\n",
    "print(f\"   Longitude range: [{member_geo_df['longitude'].min():.4f}, {member_geo_df['longitude'].max():.4f}]\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n3. Sample Member Data:\")\n",
    "print(member_geo_df.head(3))\n",
    "\n",
    "print(\"\\n4. Sample Facility Data:\")\n",
    "print(facility_df.head(3))\n",
    "\n",
    "print(\"\\n5. Sample Market Data:\")\n",
    "print(market_df.head(3))\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 3: MEMBER DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🗺️ TASK 1: MEMBER DISTRIBUTION MAPPING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate members per zip code\n",
    "zip_distribution = member_geo_df.groupby('zip_code').agg({\n",
    "    'member_id': 'count',\n",
    "    'latitude': 'mean',\n",
    "    'longitude': 'mean',\n",
    "    'membership_tier': lambda x: x.mode()[0] if len(x) > 0 else 'N/A',\n",
    "    'distance_to_gym_km': 'mean',\n",
    "    'travel_time_minutes': 'mean'\n",
    "}).rename(columns={'member_id': 'member_count'}).reset_index()\n",
    "\n",
    "print(\"\\n📊 Member Distribution by Zip Code:\")\n",
    "print(zip_distribution.sort_values('member_count', ascending=False))\n",
    "\n",
    "# Calculate density metrics\n",
    "total_members = len(member_geo_df)\n",
    "zip_distribution['member_density'] = zip_distribution['member_count'] / total_members\n",
    "zip_distribution['density_category'] = pd.cut(\n",
    "    zip_distribution['member_count'], \n",
    "    bins=[0, 2, 4, 100],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "print(f\"\\n📈 Density Distribution:\")\n",
    "print(zip_distribution['density_category'].value_counts())\n",
    "\n",
    "# Merge with market data for enhanced analysis\n",
    "distribution_enhanced = zip_distribution.merge(\n",
    "    market_df[['zip_code', 'population', 'median_income', 'fitness_interest_score']], \n",
    "    on='zip_code', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate penetration rate (members per 1000 population)\n",
    "distribution_enhanced['penetration_rate'] = (\n",
    "    distribution_enhanced['member_count'] / \n",
    "    distribution_enhanced['population'] * 1000\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 Top 5 Zip Codes by Member Penetration Rate:\")\n",
    "print(distribution_enhanced.nlargest(5, 'penetration_rate')[\n",
    "    ['zip_code', 'member_count', 'population', 'penetration_rate']\n",
    "])\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 4: DEMAND PATTERN ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 TASK 2: DEMAND ANALYSIS & HEATMAPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Analyze demand by membership tier\n",
    "tier_demand = member_geo_df.groupby('membership_tier').agg({\n",
    "    'member_id': 'count',\n",
    "    'visit_frequency': lambda x: (x == 'high').sum(),\n",
    "    'distance_to_gym_km': 'mean',\n",
    "    'travel_time_minutes': 'mean'\n",
    "}).rename(columns={\n",
    "    'member_id': 'total_members',\n",
    "    'visit_frequency': 'high_frequency_users'\n",
    "})\n",
    "\n",
    "print(\"\\n💎 Demand by Membership Tier:\")\n",
    "print(tier_demand)\n",
    "\n",
    "# Analyze demand by visit frequency\n",
    "frequency_demand = member_geo_df['visit_frequency'].value_counts()\n",
    "print(\"\\n📅 Demand by Visit Frequency:\")\n",
    "print(frequency_demand)\n",
    "\n",
    "# Calculate demand intensity score\n",
    "demand_by_zip = member_geo_df.groupby('zip_code').agg({\n",
    "    'member_id': 'count',\n",
    "    'visit_frequency': lambda x: (x == 'high').sum() / len(x),\n",
    "    'membership_tier': lambda x: (x == 'premium').sum() / len(x)\n",
    "}).rename(columns={\n",
    "    'member_id': 'member_count',\n",
    "    'visit_frequency': 'high_freq_ratio',\n",
    "    'membership_tier': 'premium_ratio'\n",
    "})\n",
    "\n",
    "# Create demand intensity score (0-100)\n",
    "demand_by_zip['demand_intensity'] = (\n",
    "    demand_by_zip['member_count'] * 0.4 +\n",
    "    demand_by_zip['high_freq_ratio'] * 30 +\n",
    "    demand_by_zip['premium_ratio'] * 30\n",
    ")\n",
    "\n",
    "demand_by_zip = demand_by_zip.reset_index()\n",
    "print(\"\\n🔥 Top 5 High-Demand Zip Codes:\")\n",
    "print(demand_by_zip.nlargest(5, 'demand_intensity'))\n",
    "\n",
    "# Analyze transportation mode preferences\n",
    "transport_analysis = member_geo_df.groupby(['zip_code', 'transportation_mode']).size().unstack(fill_value=0)\n",
    "print(\"\\n🚗 Transportation Mode Distribution by Zip:\")\n",
    "print(transport_analysis)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 5: ACCESSIBILITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚦 TASK 3: ACCESSIBILITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate accessibility metrics\n",
    "accessibility_metrics = member_geo_df.groupby('zip_code').agg({\n",
    "    'distance_to_gym_km': ['mean', 'min', 'max', 'std'],\n",
    "    'travel_time_minutes': ['mean', 'min', 'max', 'std'],\n",
    "    'member_id': 'count'\n",
    "}).round(2)\n",
    "\n",
    "accessibility_metrics.columns = ['_'.join(col).strip() for col in accessibility_metrics.columns]\n",
    "accessibility_metrics = accessibility_metrics.reset_index()\n",
    "\n",
    "print(\"\\n📍 Accessibility Metrics by Zip Code:\")\n",
    "print(accessibility_metrics)\n",
    "\n",
    "# Identify underserved areas (high travel time/distance)\n",
    "underserved_threshold_distance = member_geo_df['distance_to_gym_km'].quantile(0.75)\n",
    "underserved_threshold_time = member_geo_df['travel_time_minutes'].quantile(0.75)\n",
    "\n",
    "underserved_members = member_geo_df[\n",
    "    (member_geo_df['distance_to_gym_km'] > underserved_threshold_distance) |\n",
    "    (member_geo_df['travel_time_minutes'] > underserved_threshold_time)\n",
    "]\n",
    "\n",
    "print(f\"\\n⚠️ Underserved Areas Analysis:\")\n",
    "print(f\"   Distance Threshold: {underserved_threshold_distance:.2f} km\")\n",
    "print(f\"   Travel Time Threshold: {underserved_threshold_time:.2f} minutes\")\n",
    "print(f\"   Underserved Members: {len(underserved_members)} ({len(underserved_members)/len(member_geo_df)*100:.1f}%)\")\n",
    "\n",
    "underserved_zips = underserved_members['zip_code'].value_counts().head(5)\n",
    "print(f\"\\n🚨 Top 5 Underserved Zip Codes:\")\n",
    "print(underserved_zips)\n",
    "\n",
    "# Calculate facility accessibility scores\n",
    "for idx, facility in facility_df.iterrows():\n",
    "    facility_name = facility['facility_name']\n",
    "    facility_members = member_geo_df[member_geo_df['preferred_facility'] == facility_name]\n",
    "    \n",
    "    if len(facility_members) > 0:\n",
    "        avg_distance = facility_members['distance_to_gym_km'].mean()\n",
    "        avg_time = facility_members['travel_time_minutes'].mean()\n",
    "        print(f\"\\n🏢 {facility_name}:\")\n",
    "        print(f\"   Members: {len(facility_members)}\")\n",
    "        print(f\"   Avg Distance: {avg_distance:.2f} km\")\n",
    "        print(f\"   Avg Travel Time: {avg_time:.2f} minutes\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 6: MARKET PENETRATION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 TASK 4: MARKET PENETRATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Merge member data with market data\n",
    "penetration_analysis = market_df.copy()\n",
    "member_counts = member_geo_df['zip_code'].value_counts().to_dict()\n",
    "penetration_analysis['current_members'] = penetration_analysis['zip_code'].map(member_counts).fillna(0)\n",
    "\n",
    "# Calculate market share and penetration\n",
    "penetration_analysis['penetration_rate'] = (\n",
    "    penetration_analysis['current_members'] / \n",
    "    penetration_analysis['population'] * 1000\n",
    ")\n",
    "\n",
    "penetration_analysis['market_share_potential'] = (\n",
    "    penetration_analysis['fitness_interest_score'] * \n",
    "    penetration_analysis['population'] / 1000\n",
    ")\n",
    "\n",
    "penetration_analysis['current_share_pct'] = (\n",
    "    penetration_analysis['current_members'] / \n",
    "    penetration_analysis['market_share_potential'] * 100\n",
    ").fillna(0)\n",
    "\n",
    "print(\"\\n📊 Market Penetration Summary:\")\n",
    "print(f\"   Total Addressable Market: {penetration_analysis['population'].sum():,} people\")\n",
    "print(f\"   Current Members: {penetration_analysis['current_members'].sum():.0f}\")\n",
    "print(f\"   Average Penetration Rate: {penetration_analysis['penetration_rate'].mean():.2f} per 1000\")\n",
    "print(f\"   Average Market Share: {penetration_analysis['current_share_pct'].mean():.2f}%\")\n",
    "\n",
    "# Identify high-potential, low-penetration areas\n",
    "penetration_analysis['opportunity_score'] = (\n",
    "    penetration_analysis['market_share_potential'] * 0.4 +\n",
    "    (100 - penetration_analysis['current_share_pct']) * 0.3 +\n",
    "    (1 - penetration_analysis['competitor_density']) * 30\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 Top 10 Market Opportunity Zip Codes:\")\n",
    "top_opportunities = penetration_analysis.nlargest(10, 'opportunity_score')[\n",
    "    ['zip_code', 'population', 'current_members', 'penetration_rate', \n",
    "     'competitor_density', 'opportunity_score', 'expansion_priority']\n",
    "]\n",
    "print(top_opportunities)\n",
    "\n",
    "# Competitive analysis\n",
    "print(\"\\n⚔️ Competitive Landscape:\")\n",
    "competitive_summary = penetration_analysis.groupby('expansion_priority').agg({\n",
    "    'zip_code': 'count',\n",
    "    'population': 'sum',\n",
    "    'current_members': 'sum',\n",
    "    'competitor_density': 'mean',\n",
    "    'fitness_interest_score': 'mean'\n",
    "}).round(2)\n",
    "print(competitive_summary)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 7: EXPANSION PLANNING ALGORITHMS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚀 TASK 5: EXPANSION PLANNING & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create expansion scoring model\n",
    "expansion_candidates = penetration_analysis.copy()\n",
    "\n",
    "# Calculate weighted expansion score\n",
    "expansion_candidates['expansion_score'] = (\n",
    "    expansion_candidates['population'] / 10000 * 20 +  # Population weight\n",
    "    expansion_candidates['median_income'] / 100000 * 15 +  # Income weight\n",
    "    expansion_candidates['age_18_35_pct'] * 100 * 15 +  # Age demographic weight\n",
    "    expansion_candidates['fitness_interest_score'] * 100 * 25 +  # Fitness interest weight\n",
    "    (1 - expansion_candidates['competitor_density']) * 25  # Low competition weight\n",
    ")\n",
    "\n",
    "# Adjust for current presence\n",
    "expansion_candidates.loc[expansion_candidates['current_members'] > 0, 'expansion_score'] *= 0.5\n",
    "\n",
    "# Filter high-priority candidates\n",
    "high_priority = expansion_candidates[\n",
    "    (expansion_candidates['expansion_score'] > expansion_candidates['expansion_score'].quantile(0.7)) &\n",
    "    (expansion_candidates['current_members'] == 0)\n",
    "].sort_values('expansion_score', ascending=False)\n",
    "\n",
    "print(\"\\n🎯 TOP 5 EXPANSION RECOMMENDATIONS:\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in high_priority.head(5).iterrows():\n",
    "    print(f\"\\n#{idx+1}. Zip Code: {row['zip_code']}\")\n",
    "    print(f\"   City: {row['city']}, {row['state']}\")\n",
    "    print(f\"   Population: {row['population']:,}\")\n",
    "    print(f\"   Median Income: ${row['median_income']:,}\")\n",
    "    print(f\"   Fitness Interest: {row['fitness_interest_score']:.2f}\")\n",
    "    print(f\"   Competitor Density: {row['competitor_density']:.2f}\")\n",
    "    print(f\"   Expansion Score: {row['expansion_score']:.1f}\")\n",
    "    print(f\"   Priority: {row['expansion_priority']}\")\n",
    "    \n",
    "    # Estimate potential members\n",
    "    potential_members = row['population'] * row['fitness_interest_score'] * 0.02\n",
    "    print(f\"   Estimated Potential Members: {potential_members:.0f}\")\n",
    "    \n",
    "    # ROI estimation\n",
    "    estimated_revenue = potential_members * 600  # Avg annual revenue per member\n",
    "    facility_cost = 500000  # Estimated facility setup cost\n",
    "    roi_years = facility_cost / estimated_revenue if estimated_revenue > 0 else 999\n",
    "    print(f\"   Estimated Annual Revenue: ${estimated_revenue:,.0f}\")\n",
    "    print(f\"   ROI Payback Period: {roi_years:.1f} years\")\n",
    "\n",
    "# Clustering analysis for optimal facility placement\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"📍 OPTIMAL FACILITY PLACEMENT ANALYSIS (K-Means Clustering)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Prepare data for clustering\n",
    "cluster_data = expansion_candidates[expansion_candidates['current_members'] == 0].copy()\n",
    "features_for_clustering = cluster_data[['population', 'median_income', 'fitness_interest_score']].copy()\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features_for_clustering)\n",
    "\n",
    "# Perform K-Means clustering (3 clusters for 3 potential new facilities)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_data['cluster'] = kmeans.fit_predict(features_normalized)\n",
    "\n",
    "print(\"\\n🎯 Recommended Facility Clusters:\")\n",
    "for cluster_id in range(3):\n",
    "    cluster_zips = cluster_data[cluster_data['cluster'] == cluster_id]\n",
    "    best_location = cluster_zips.nlargest(1, 'expansion_score').iloc[0]\n",
    "    \n",
    "    print(f\"\\n   Cluster {cluster_id + 1}: Zip Code {best_location['zip_code']}\")\n",
    "    print(f\"   Total Population in Cluster: {cluster_zips['population'].sum():,}\")\n",
    "    print(f\"   Average Income: ${cluster_zips['median_income'].mean():,.0f}\")\n",
    "    print(f\"   Avg Fitness Interest: {cluster_zips['fitness_interest_score'].mean():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 8: INTERACTIVE FOLIUM MAPS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🗺️ GENERATING INTERACTIVE FOLIUM MAPS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Map 1: Member Distribution Map with Facilities\n",
    "print(\"\\n1. Creating Member Distribution Map...\")\n",
    "center_lat = member_geo_df['latitude'].mean()\n",
    "center_lng = member_geo_df['longitude'].mean()\n",
    "\n",
    "member_map = folium.Map(\n",
    "    location=[center_lat, center_lng],\n",
    "    zoom_start=12,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Add facility markers\n",
    "for idx, facility in facility_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[facility['latitude'], facility['longitude']],\n",
    "        popup=f\"\"\"\n",
    "        <b>{facility['facility_name']}</b><br>\n",
    "        Capacity: {facility['capacity']}<br>\n",
    "        Members: {facility['current_members']}<br>\n",
    "        Utilization: {facility['utilization_rate']*100:.0f}%<br>\n",
    "        Market Share: {facility['market_share']*100:.0f}%\n",
    "        \"\"\",\n",
    "        icon=folium.Icon(color='red', icon='home', prefix='fa'),\n",
    "        tooltip=facility['facility_name']\n",
    "    ).add_to(member_map)\n",
    "\n",
    "# Add member markers with clustering\n",
    "member_cluster = MarkerCluster(name='Members').add_to(member_map)\n",
    "\n",
    "for idx, member in member_geo_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[member['latitude'], member['longitude']],\n",
    "        radius=5,\n",
    "        popup=f\"\"\"\n",
    "        Member ID: {member['member_id']}<br>\n",
    "        Tier: {member['membership_tier']}<br>\n",
    "        Distance: {member['distance_to_gym_km']:.1f} km<br>\n",
    "        Travel Time: {member['travel_time_minutes']} min<br>\n",
    "        Frequency: {member['visit_frequency']}\n",
    "        \"\"\",\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fillOpacity=0.6\n",
    "    ).add_to(member_cluster)\n",
    "\n",
    "# Add heatmap layer\n",
    "heat_data = [[row['latitude'], row['longitude']] for idx, row in member_geo_df.iterrows()]\n",
    "HeatMap(heat_data, name='Member Density Heatmap', radius=15, blur=25).add_to(member_map)\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(member_map)\n",
    "\n",
    "# Save map\n",
    "member_map.save('member_distribution_map.html')\n",
    "print(\"   ✅ Saved: member_distribution_map.html\")\n",
    "\n",
    "# Map 2: Expansion Opportunity Map\n",
    "print(\"\\n2. Creating Expansion Opportunity Map...\")\n",
    "expansion_map = folium.Map(\n",
    "    location=[center_lat, center_lng],\n",
    "    zoom_start=11,\n",
    "    tiles='CartoDB positron'\n",
    ")\n",
    "\n",
    "# Add existing facilities\n",
    "for idx, facility in facility_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[facility['latitude'], facility['longitude']],\n",
    "        popup=f\"<b>Existing: {facility['facility_name']}</b>\",\n",
    "        icon=folium.Icon(color='green', icon='check', prefix='fa')\n",
    "    ).add_to(expansion_map)\n",
    "\n",
    "# Add top expansion opportunities\n",
    "for idx, location in high_priority.head(10).iterrows():\n",
    "    # Get approximate coordinates for zip code centroid\n",
    "    zip_members = member_geo_df[member_geo_df['zip_code'] == location['zip_code']]\n",
    "    if len(zip_members) > 0:\n",
    "        lat = zip_members['latitude'].mean()\n",
    "        lng = zip_members['longitude'].mean()\n",
    "    else:\n",
    "        # Use facility average if no members in that zip\n",
    "        lat = facility_df['latitude'].mean()\n",
    "        lng = facility_df['longitude'].mean()\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lng],\n",
    "        radius=location['expansion_score'] / 5,\n",
    "        popup=f\"\"\"\n",
    "        <b>Expansion Opportunity</b><br>\n",
    "        Zip: {location['zip_code']}<br>\n",
    "        Population: {location['population']:,}<br>\n",
    "        Score: {location['expansion_score']:.1f}<br>\n",
    "        Priority: {location['expansion_priority']}\n",
    "        \"\"\",\n",
    "        color='orange',\n",
    "        fill=True,\n",
    "        fillColor='yellow',\n",
    "        fillOpacity=0.7\n",
    "    ).add_to(expansion_map)\n",
    "\n",
    "expansion_map.save('expansion_opportunities_map.html')\n",
    "print(\"   ✅ Saved: expansion_opportunities_map.html\")\n",
    "\n",
    "# Map 3: Accessibility & Underserved Areas\n",
    "print(\"\\n3. Creating Accessibility Analysis Map...\")\n",
    "accessibility_map = folium.Map(\n",
    "    location=[center_lat, center_lng],\n",
    "    zoom_start=12,\n",
    "    tiles='OpenStreetMap'\n",
    ")\n",
    "\n",
    "# Add facilities\n",
    "for idx, facility in facility_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[facility['latitude'], facility['longitude']],\n",
    "        popup=f\"<b>{facility['facility_name']}</b>\",\n",
    "        icon=folium.Icon(color='darkblue', icon='home', prefix='fa')\n",
    "    ).add_to(accessibility_map)\n",
    "\n",
    "# Color code members by accessibility\n",
    "for idx, member in member_geo_df.iterrows():\n",
    "    if member['distance_to_gym_km'] > underserved_threshold_distance:\n",
    "        color = 'red'\n",
    "        category = 'Underserved (High Distance)'\n",
    "    elif member['travel_time_minutes'] > underserved_threshold_time:\n",
    "        color = 'orange'\n",
    "        category = 'Moderate Access'\n",
    "    else:\n",
    "        color = 'green'\n",
    "        category = 'Well Served'\n",
    "    \n",
    "    folium.CircleMarker(\n",
    "        location=[member['latitude'], member['longitude']],\n",
    "        radius=4,\n",
    "        popup=f\"\"\"\n",
    "        {category}<br>\n",
    "        Distance: {member['distance_to_gym_km']:.1f} km<br>\n",
    "        Travel: {member['travel_time_minutes']} min<br>\n",
    "        Transport: {member['transportation_mode']}\n",
    "        \"\"\",\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fillOpacity=0.7\n",
    "    ).add_to(accessibility_map)\n",
    "\n",
    "accessibility_map.save('accessibility_analysis_map.html')\n",
    "print(\"   ✅ Saved: accessibility_analysis_map.html\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 9: STATISTICAL INSIGHTS & RECOMMENDATIONS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📈 STATISTICAL INSIGHTS & STRATEGIC RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Key Performance Indicators\n",
    "print(\"\\n🎯 KEY PERFORMANCE INDICATORS:\")\n",
    "print(f\"   Total Members: {len(member_geo_df)}\")\n",
    "print(f\"   Total Facilities: {len(facility_df)}\")\n",
    "print(f\"   Average Distance to Gym: {member_geo_df['distance_to_gym_km'].mean():.2f} km\")\n",
    "print(f\"   Average Travel Time: {member_geo_df['travel_time_minutes'].mean():.1f} minutes\")\n",
    "print(f\"   Member Concentration: {len(member_geo_df['zip_code'].unique())} zip codes\")\n",
    "print(f\"   Average Facility Utilization: {facility_df['utilization_rate'].mean()*100:.1f}%\")\n",
    "\n",
    "# Distribution insights\n",
    "print(\"\\n📊 DISTRIBUTION INSIGHTS:\")\n",
    "tier_dist = member_geo_df['membership_tier'].value_counts()\n",
    "print(f\"   Premium Members: {tier_dist.get('premium', 0)} ({tier_dist.get('premium', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "print(f\"   Standard Members: {tier_dist.get('standard', 0)} ({tier_dist.get('standard', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "print(f\"   Basic Members: {tier_dist.get('basic', 0)} ({tier_dist.get('basic', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "\n",
    "freq_dist = member_geo_df['visit_frequency'].value_counts()\n",
    "print(f\"\\n   High Frequency: {freq_dist.get('high', 0)} ({freq_dist.get('high', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "print(f\"   Medium Frequency: {freq_dist.get('medium', 0)} ({freq_dist.get('medium', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "print(f\"   Low Frequency: {freq_dist.get('low', 0)} ({freq_dist.get('low', 0)/len(member_geo_df)*100:.1f}%)\")\n",
    "\n",
    "# Strategic recommendations\n",
    "print(\"\\n💡 STRATEGIC RECOMMENDATIONS:\")\n",
    "print(\"\\n1. IMMEDIATE ACTIONS:\")\n",
    "print(\"   • Focus on underserved zip codes with high travel times\")\n",
    "print(\"   • Improve transportation options for members >30 min travel time\")\n",
    "print(\"   • Target premium membership sales in high-income areas\")\n",
    "\n",
    "print(\"\\n2. SHORT-TERM (3-6 months):\")\n",
    "print(\"   • Launch targeted marketing in top 5 expansion zip codes\")\n",
    "print(\"   • Analyze facility capacity constraints at gym_main (90% utilization)\")\n",
    "print(\"   • Implement shuttle service for underserved areas\")\n",
    "\n",
    "print(\"\\n3. LONG-TERM (6-12 months):\")\n",
    "top_expansion = high_priority.head(1).iloc[0]\n",
    "print(f\"   • Open new facility in Zip Code {top_expansion['zip_code']} (highest expansion score)\")\n",
    "print(\"   • Expand capacity at gym_main to accommodate growing demand\")\n",
    "print(\"   • Develop strategic partnerships in high-competitor areas\")\n",
    "\n",
    "print(\"\\n4. MARKET PENETRATION STRATEGY:\")\n",
    "print(\"   • Current market penetration: Low in several high-potential areas\")\n",
    "print(\"   • Opportunity: 10+ zip codes with <2 members but high fitness interest\")\n",
    "print(\"   • Recommendation: Launch neighborhood ambassador program\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 10: EXPORT RESULTS FOR DASHBOARD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"💾 EXPORTING RESULTS FOR STREAMLIT DASHBOARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Export processed datasets\n",
    "distribution_enhanced.to_csv('processed_member_distribution.csv', index=False)\n",
    "print(\"✅ Exported: processed_member_distribution.csv\")\n",
    "\n",
    "demand_by_zip.to_csv('processed_demand_analysis.csv', index=False)\n",
    "print(\"✅ Exported: processed_demand_analysis.csv\")\n",
    "\n",
    "accessibility_metrics.to_csv('processed_accessibility_metrics.csv', index=False)\n",
    "print(\"✅ Exported: processed_accessibility_metrics.csv\")\n",
    "\n",
    "penetration_analysis.to_csv('processed_market_penetration.csv', index=False)\n",
    "print(\"✅ Exported: processed_market_penetration.csv\")\n",
    "\n",
    "high_priority.to_csv('expansion_recommendations.csv', index=False)\n",
    "print(\"✅ Exported: expansion_recommendations.csv\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary_stats = {\n",
    "    'total_members': len(member_geo_df),\n",
    "    'total_facilities': len(facility_df),\n",
    "    'avg_distance_km': float(member_geo_df['distance_to_gym_km'].mean()),\n",
    "    'avg_travel_time': float(member_geo_df['travel_time_minutes'].mean()),\n",
    "    'unique_zip_codes': len(member_geo_df['zip_code'].unique()),\n",
    "    'avg_utilization': float(facility_df['utilization_rate'].mean()),\n",
    "    'underserved_members': len(underserved_members),\n",
    "    'top_expansion_zip': str(top_expansion['zip_code']),\n",
    "    'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('geo_analytics_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=4)\n",
    "print(\"✅ Exported: geo_analytics_summary.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ GEO ANALYTICS ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n📁 Generated Files:\")\n",
    "print(\"   • member_distribution_map.html\")\n",
    "print(\"   • expansion_opportunities_map.html\")\n",
    "print(\"   • accessibility_analysis_map.html\")\n",
    "print(\"   • processed_member_distribution.csv\")\n",
    "print(\"   • processed_demand_analysis.csv\")\n",
    "print(\"   • processed_accessibility_metrics.csv\")\n",
    "print(\"   • processed_market_penetration.csv\")\n",
    "print(\"   • expansion_recommendations.csv\")\n",
    "print(\"   • geo_analytics_summary.json\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"   1. Review interactive HTML maps for visual insights\")\n",
    "print(\"   2. Load processed CSV files into Streamlit dashboard\")\n",
    "print(\"   3. Present expansion recommendations to stakeholders\")\n",
    "print(\"   4. Implement strategic actions based on findings\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
